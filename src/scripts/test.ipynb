{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189f8d12-92ce-4200-820e-50372fd1311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6043ec-95a6-452c-9496-623299db2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_prompt(file_path): #Plug in path to csv\n",
    "    df = pd.read_csv(file_path)\n",
    "    questions = df[\"Model Questions\"]\n",
    "    meta_prompt = \"\"\"Given the following group of statements, classify a user statement into most similar group, if there are no matches, output 0 for question group, use the \"classify\" function provided:\\nList of groups: \"\"\"\n",
    "    for i, question in enumerate(questions):\n",
    "        group = str(i) + \": \" + question\n",
    "        meta_prompt += group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2e46b6-620c-4c95-a1d9-01f26ad44367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f05b368-3dec-46d2-8d30-cdd431262364",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'doormanFailure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslackeventsapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SlackEventAdapter\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdoormanFailure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m logs\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_exists_in_json\u001b[39m(file_path, value):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'doormanFailure'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import slack\n",
    "import openai\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask\n",
    "from slackeventsapi import SlackEventAdapter\n",
    "import pandas as pd\n",
    "from doormanFailure import *\n",
    "\n",
    "global logs\n",
    "def value_exists_in_json(file_path, value):\n",
    "    data = load_json_from_file(file_path)\n",
    "    print(data)\n",
    "    #return value == data\n",
    "\n",
    "def write_json_to_file(data, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "def load_json_from_file(file_path):\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['logs']\n",
    "\n",
    "def append_log(logs, t_id, role, content):\n",
    "    for log in logs:\n",
    "        if (log['t_id'] == t_id):\n",
    "            log['thread_log'].append({\"role\": role, \"content\": cLastontent})\n",
    "            return logs\n",
    "    new_log = {\n",
    "        \"t_id\": t_id,\n",
    "        \"thread_log\": [\n",
    "            {\"role\": role, \"content\": content}\n",
    "        ],\n",
    "    }\n",
    "    logs.append(new_log)\n",
    "    return logs\n",
    "def load_log(logs, t_id):\n",
    "    for log in logs:\n",
    "        if (log['t_id'] == t_id):\n",
    "            return log['thread_log']\n",
    "    return []\n",
    "\n",
    "def doorman_v0(t_id, prompt, answers):\n",
    "    global logs\n",
    "    # Function params, mess around with these to experiment with model behvior\n",
    "    null_response = \"I'm sorry, could you provide more clarifying information?\"\n",
    "    max_tokens = 100\n",
    "    temperature = 0.8\n",
    "    with open('llmlads_prompt.txt','r') as file:\n",
    "        meta_prompt = file.read()\n",
    "    # Load thread log if exists\n",
    "    system_prompt = np.array([{\"role\": \"system\", \"content\": meta_prompt}])\n",
    "    user_prompt = np.array([{\"role\": \"user\", \"content\": prompt}])\n",
    "    thread_log = np.array(load_log(logs, t_id))\n",
    "    messages = np.concatenate((system_prompt, thread_log, user_prompt)).tolist()\n",
    "    #print(messages)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo-16k\",\n",
    "        messages = messages,\n",
    "        functions = [\n",
    "            {\n",
    "                \"name\": \"classify\",\n",
    "                \"description\": \"classify a user statement into one of the statement groups using a json format, output 0 if there are no matches\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"group\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"index of group that the statement most resembles\",\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"group\"],\n",
    "            },\n",
    "        ],\n",
    "        function_call=\"auto\",\n",
    "        max_tokens = 100,\n",
    "        temperature = 0.8,\n",
    "    )\n",
    "    try:\n",
    "        if (response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"] != \"{}\"):\n",
    "            index = int(response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"][13:-2])\n",
    "            answer = answers[index - 1]\n",
    "            logs = append_log(logs, t_id, \"user\", prompt)\n",
    "            logs = append_log(logs, t_id, \"assistant\", answer)\n",
    "            return index\n",
    "        else:\n",
    "            print(logs)\n",
    "            logs = append_log(logs, t_id, \"user\", prompt)\n",
    "            print(logs)\n",
    "            logs = append_log(logs, t_id, \"assistant\", null_response)\n",
    "            print(\"Null response returned\")\n",
    "            return 0\n",
    "    except:\n",
    "        logs = append_log(logs, t_id, \"user\", prompt)\n",
    "        logs = append_log(logs, t_id, \"assistant\", null_response)\n",
    "        print(\"<dev flag> Function wasn't even called lol\")\n",
    "        return 0\n",
    "    \n",
    "################################################\n",
    "#### surround this code with __name__ block ####\n",
    "################################################\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('QandA_list.csv', encoding='utf-8')\n",
    "    answers = df[\"Question answers\"].tolist()\n",
    "    env_path = Path('.')/'.env'\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "    openai.api_key = token=os.environ['CHAT_TOKEN']\n",
    "    try:\n",
    "        logs = load_json_from_file(\"doorman_log.json\")\n",
    "        while(True):\n",
    "            t_id = int(input(\"Thread ID: \"))\n",
    "            prompt = input(\"User prompt: \")\n",
    "            index = doorman_v0(logs, t_id, prompt, answers)\n",
    "            if index == 0:\n",
    "                print(\"Not found\")\n",
    "            else:\n",
    "                print(\"Found\")\n",
    "                print(answers[index-1])\n",
    "            write_json_to_file({\"logs\" :logs}, \"doorman_log.json\")\n",
    "    except:\n",
    "        if os.path.isfile(\"doorman_log.json\"):\n",
    "            print(\"<dev flag> something went wrong, but doorman_log.json exists\")\n",
    "        else:\n",
    "            print(\"<dev flag> doorman log not found, making empty file called doorman_log.json\")\n",
    "            logs = {\"logs\" : []}\n",
    "            write_json_to_file(logs, \"doorman_log.json\")\n",
    "\"\"\"\n",
    "################################################\n",
    "################################################\n",
    "################################################\n",
    "def doormanWMemory(input,thread_id):\n",
    "    global logs\n",
    "    df = pd.read_csv('QandA_list.csv', encoding='utf-8')\n",
    "    answers = df[\"Question answers\"].tolist()\n",
    "    try:\n",
    "        logs = load_json_from_file(\"doorman_log.json\")\n",
    "        t_id = thread_id\n",
    "        prompt = input\n",
    "        index = doorman_v0(t_id, prompt, answers)\n",
    "        print(logs)\n",
    "        if index == 0:\n",
    "            print(\"Not found\")\n",
    "            write_json_to_file({\"logs\" :logs}, \"doorman_log.json\")\n",
    "            return(doormanFailure())\n",
    "        else:\n",
    "            print(\"Found\")\n",
    "            write_json_to_file({\"logs\" :logs}, \"doorman_log.json\")\n",
    "            return(answers[index-1])\n",
    "    except Exception as e:\n",
    "        if os.path.isfile(\"doorman_log.json\"):\n",
    "            print(\"<dev flag> something went wrong, but doorman_log.json exists\")\n",
    "            print(e)\n",
    "        else:\n",
    "            print(\"<dev flag> doorman log not found, making empty file called doorman_log.json\")\n",
    "            logs = {\"logs\" : []}\n",
    "            write_json_to_file(logs, \"doorman_log.json\")\n",
    "            return doormanWMemory(input,thread_id)\n",
    "\n",
    "def checkFor(data):\n",
    "    return value_exists_in_json(\"doorman_log.json\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e685daf-7abd-418f-8e38-6bf452e5bcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Question Categories', 'Question answers', 'Model Questions',\n",
      "       'Keywords'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def formatted_time():\n",
    "    now =                       datetime.now()\n",
    "    formatted_time =            now.strftime('%H-%M-%d-%m-%Y')\n",
    "    return formatted_time\n",
    "def append_question(\n",
    "                    question_categories = \"\", # title of question set\n",
    "                    question_answers= \"\", # answer to be given by Doorman\n",
    "                    model_questions= \"\", # question set to be plugged into doorman\n",
    "                    keywords = [\"\"], # keywords associated with question set (optional)\n",
    "                    filepath = \"QandA_list.csv\",): # path to the csv\n",
    "    data = pd.read_csv(filepath)\n",
    "    print(data.keys())\n",
    "    new_row = {'Question Categories': question_categories,\n",
    "               'Question answers': question_answers,\n",
    "               'Model Questions': model_questions,\n",
    "               'Keywords': keywords\n",
    "              }\n",
    "    data = pd.concat([data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    return data\n",
    "    \"\"\"\n",
    "    except:\n",
    "        print(\"File not found, please fix filepath to csv\")\n",
    "        return None\n",
    "    \"\"\"\n",
    "# To use this function, first create a ./backup/ directory where you are running the script\n",
    "def save_csv(data, filepath = \"QandA_list.csv\", backup = True):\n",
    "    old_data = pd.read_csv(filepath)\n",
    "    data.to_csv(filepath, index=False)\n",
    "    if backup == True:\n",
    "        backup_path = \"./backup/\" + formatted_time() + \"_QandA_list.csv\"\n",
    "        old_data.to_csv(backup_path)\n",
    "def remove_question(data, index):\n",
    "    return data.drop([data.index[index]])\n",
    "\n",
    "# todo: add these functions after Mateo figures out the modal stuff\n",
    "def edit_question():\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'QandA_list.csv'\n",
    "    data = pd.read_csv(filepath)\n",
    "    print(data.keys())\n",
    "    \"\"\"\n",
    "    data = append_question(\n",
    "        question_categories = \"Add TA to iCollege\",\n",
    "        question_answers = \"Fill out a request form: https://gsutech.service-now.com/sp?id=sc_cat_item&sys_id=6dbd8365db501340601b502bdc9619dc\",\n",
    "        model_questions = (\n",
    "            \"How to add a TA with admin rights to my class?\"\n",
    "            \"Add a TA with full access to my class on icollege?\"\n",
    "            \"How to grant admin rights to my TA so they can manage the class?\"\n",
    "            \"How can I enable my TA to enter grades?\"\n",
    "        ),\n",
    "        keywords = [\"TA\", \"teaching assistant\", \"iCollege access\"]\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    data = remove_question(data, 28)\n",
    "    save_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b248d729-26bc-4a75-8382-2334b881bb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Question Categories', 'Question answers', 'Model Questions',\n",
      "       'Keywords'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
