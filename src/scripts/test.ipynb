{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189f8d12-92ce-4200-820e-50372fd1311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6043ec-95a6-452c-9496-623299db2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_prompt(file_path): #Plug in path to csv\n",
    "    df = pd.read_csv(file_path)\n",
    "    questions = df[\"Model Questions\"]\n",
    "    meta_prompt = \"\"\"Given the following group of statements, classify a user statement into most similar group, if there are no matches, output 0 for question group, use the \"classify\" function provided:\\nList of groups: \"\"\"\n",
    "    for i, question in enumerate(questions):\n",
    "        group = str(i) + \": \" + question\n",
    "        meta_prompt += group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2e46b6-620c-4c95-a1d9-01f26ad44367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import slack\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask\n",
    "from slackeventsapi import SlackEventAdapter\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import requests\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "env_path = Path('.')/'.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "openai.api_key = token=os.environ['CHAT_TOKEN']\n",
    "\n",
    "def get_html(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    html_content = response.read().decode(\"utf-8\")\n",
    "    return html_content\n",
    "def get_pdf_text(url):\n",
    "    arxiv_id = url[22:]\n",
    "    url = \"https://arxiv.org/pdf/\" + arxiv_id + \".pdf\"\n",
    "    response = requests.get(url)\n",
    "    # Ensure the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Step 2: Converting the PDF to a more readable format\n",
    "        with BytesIO(response.content) as open_pdf_file:\n",
    "            read_pdf = PyPDF2.PdfReader(open_pdf_file)\n",
    "            num_pages = len(read_pdf.pages)\n",
    "            # Step 3: Extracting the text\n",
    "            text_content = \"\"\n",
    "            for i in range(num_pages):\n",
    "                page = read_pdf.pages[i]\n",
    "                text_content += page.extract_text()\n",
    "        return(text_content)\n",
    "    else:\n",
    "        return(\"Pattern not found [Failed match flag]\")\n",
    "def fetch_abstract_from_html(url):\n",
    "    pattern = r'<meta property=\"og:description\" content=\"(.*?)\"/>'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.search(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Pdf not found [Failed match flag]\")\n",
    "def fetch_abstract(text):\n",
    "    #print(text)\n",
    "    pattern = r'Abstract(.*?).\\n1'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Conclusion not found [Failed match flag]\")\n",
    "def fetch_conclusion(text):\n",
    "    #print(text)\n",
    "    pattern = r'Conclusion(.*?)Acknowledgments'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Conclusion not found [Failed match flag]\")\n",
    "def fetch_introduction(text):\n",
    "    #eturn(text)\n",
    "    pattern = r'Introduction(.*?).\\n2'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Introduction not found [Failed match flag]\")\n",
    "def remove_newlinechar(user_message):\n",
    "    pattern = r'\\n'\n",
    "    match = re.search(pattern, user_message, re.DOTALL)\n",
    "    if match:\n",
    "        pings = match.group(0)\n",
    "        user_message = user_message.replace(str(pings), \" \")\n",
    "    return(user_message)\n",
    "def fetch_authors_from_html(url):\n",
    "    pattern = r'<meta name=\"citation_author\" content=\"(.*?)\" />'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.findall(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        return(match)\n",
    "    else:\n",
    "        return(\"Authors not found [Failed match flag]\")\n",
    "def fetch_title_from_html(url):\n",
    "    pattern = r'<meta name=\"twitter:title\" content=\"(.*?)\"/>'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.search(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Title not found [Failed match flag]\")\n",
    "    \n",
    "def dumb_this_down(text, age):\n",
    "    system_prompt = \"Given the following text from a paper, summarize it so that a \" + str(age) + \" year old could read it\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo-16k\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ],\n",
    "    max_tokens = 100,\n",
    "    temperature = 0.8,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "################################################\n",
    "###########  FUNCTIONS FOR MATEO  ##############\n",
    "################################################\n",
    "def get_title(url):\n",
    "    return fetch_title_from_html(url)\n",
    "def get_authors(url):\n",
    "    return fetch_authors_from_html(url)\n",
    "def get_abstract(url):\n",
    "    return fetch_abstract_from_html(url)\n",
    "def get_introduction(url):\n",
    "    return remove_newlinechar(fetch_introduction(get_pdf_text(url)))\n",
    "def get_conclusion(url):\n",
    "    return fetch_conclusion(remove_newlinechar(get_pdf_text(url)))\n",
    "def dumb_down_abstract(url):\n",
    "    return remove_newlinechar(dumb_this_down(get_abstract(url), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f05b368-3dec-46d2-8d30-cdd431262364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper is about a new random model for links called the random meander link model. The authors use meander diagrams, which are pairs of curves in the plane, to represent links. They prove that this model produces non-trivial links with high probability and that it yields infinitely many distinct links. They also show how this model can be used to calculate the expected number of twists in a random link diagram. The authors conclude with some open questions about the hyperbolicity and volume of random meander links. One advantage of this model is that it relates to a well-known combinatorial problem about matching pairs of parentheses. Overall, this paper shows how tools from combinatorics can be used to investigate properties of links.\n"
     ]
    }
   ],
   "source": [
    "import slack\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask\n",
    "from slackeventsapi import SlackEventAdapter\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import requests\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "env_path = Path('.')/'.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "openai.api_key = token=os.environ['CHAT_TOKEN']\n",
    "\n",
    "def get_html(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    html_content = response.read().decode(\"utf-8\")\n",
    "    return html_content\n",
    "def get_pdf_text(url):\n",
    "    arxiv_id = url[22:]\n",
    "    url = \"https://arxiv.org/pdf/\" + arxiv_id + \".pdf\"\n",
    "    response = requests.get(url)\n",
    "    # Ensure the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Step 2: Converting the PDF to a more readable format\n",
    "        with BytesIO(response.content) as open_pdf_file:\n",
    "            read_pdf = PyPDF2.PdfReader(open_pdf_file)\n",
    "            num_pages = len(read_pdf.pages)\n",
    "            # Step 3: Extracting the text\n",
    "            text_content = \"\"\n",
    "            for i in range(num_pages):\n",
    "                page = read_pdf.pages[i]\n",
    "                text_content += page.extract_text()\n",
    "        return(text_content)\n",
    "    else:\n",
    "        return(\"Pattern not found [Failed match flag]\")\n",
    "def fetch_abstract_from_html(url):\n",
    "    pattern = r'<meta property=\"og:description\" content=\"(.*?)\"/>'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.search(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Pdf not found [Failed match flag]\")\n",
    "def fetch_abstract(text):\n",
    "    #print(text)\n",
    "    pattern = r'Abstract(.*?).\\n1'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Conclusion not found [Failed match flag]\")\n",
    "def fetch_conclusion(text):\n",
    "    #print(text)\n",
    "    pattern = r'Conclusion(.*?)Acknowledgments'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Conclusion not found [Failed match flag]\")\n",
    "def fetch_introduction(text):\n",
    "    #eturn(text)\n",
    "    pattern = r'Introduction(.*?).\\n2'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Introduction not found [Failed match flag]\")\n",
    "def remove_newlinechar(user_message):\n",
    "    pattern = r'\\n'\n",
    "    match = re.search(pattern, user_message, re.DOTALL)\n",
    "    if match:\n",
    "        pings = match.group(0)\n",
    "        user_message = user_message.replace(str(pings), \" \")\n",
    "    return(user_message)\n",
    "def fetch_authors_from_html(url):\n",
    "    pattern = r'<meta name=\"citation_author\" content=\"(.*?)\" />'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.findall(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        return(match)\n",
    "    else:\n",
    "        return(\"Authors not found [Failed match flag]\")\n",
    "def fetch_title_from_html(url):\n",
    "    pattern = r'<meta name=\"twitter:title\" content=\"(.*?)\"/>'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.search(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Title not found [Failed match flag]\")\n",
    "    \n",
    "def dumb_this_down(text, age):\n",
    "    system_prompt = \"Given the following text from a paper, summarize it so that a \" + str(age) + \" year old could read it\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo-16k\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ],\n",
    "    max_tokens = 100,\n",
    "    temperature = 0.8,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "################################################\n",
    "###########  FUNCTIONS FOR MATEO  ##############\n",
    "################################################\n",
    "def get_title(url):\n",
    "    return fetch_title_from_html(url)\n",
    "def get_authors(url):\n",
    "    return fetch_authors_from_html(url)\n",
    "def get_abstract(url):\n",
    "    return fetch_abstract_from_html(url)\n",
    "def get_introduction(url):\n",
    "    return remove_newlinechar(fetch_introduction(get_pdf_text(url)))\n",
    "def get_conclusion(url):\n",
    "    return fetch_conclusion(remove_newlinechar(get_pdf_text(url)))\n",
    "def fetch_everything(url):\n",
    "    pdf = get_pdf_text(url)\n",
    "    content = {}\n",
    "    content[\"title\"] = get_title(url)\n",
    "    content[\"authors\"] = get_authors(url)\n",
    "    content[\"abstract\"] =  get_abstract(url)\n",
    "    content[\"introduction\"] = fetch_introduction(pdf)\n",
    "    content[\"conclusion\"] =  fetch_conclusion(pdf)\n",
    "    return content\n",
    "test_url = \"https://arxiv.org/abs/2205.03451\"\n",
    "\n",
    "def append_title(meta_prompt, title):\n",
    "    if (\"[Failed match flag]\" not in title):\n",
    "        meta_prompt += \"Summarize the following paper titled \\\"\" + title + \"\\\" \"\n",
    "    else:\n",
    "        meta_prompt += \"Summarize the following paper \"\n",
    "    return meta_prompt\n",
    "def append_authors(meta_prompt, authors):\n",
    "    if (\"[Failed match flag]\" in authors):\n",
    "        return meta_prompt\n",
    "    if (len(authors) == 1):\n",
    "        return meta_prompt + \"writen by \" + author + \" \"\n",
    "    meta_prompt += \"written by \"\n",
    "    for i in range(len(authors)-1):\n",
    "        meta_prompt += authors[i] + \", \"\n",
    "    meta_prompt += authors[-1] + \" \"\n",
    "    return meta_prompt\n",
    "# Levels = [\"child\", \"teenager\", \"undergraduate\", \"graduate\", \"phd\"]\n",
    "def append_level(meta_prompt, level):\n",
    "    if level == \"child\":\n",
    "        return meta_prompt + \"such that a child could understand it:\\n\"\n",
    "    if level == \"teenager\":\n",
    "        return meta_prompt + \"such that a teenager could understand it:\\n\"\n",
    "    if level == \"undergraduate\":\n",
    "        return meta_prompt + \"at the level of an undergraduate:\\n\"\n",
    "    if level == \"graduate\":\n",
    "        return meta_prompt + \"to a graduate or masters program audience:\\n\"\n",
    "    if level == \"phd\":\n",
    "        return meta_prompt + \"to a phd, do not leave out technicalities:\\n\"\n",
    "def append_abstract(meta_prompt, abstract):\n",
    "    if (\"[Failed match flag]\" in abstract):\n",
    "        return meta_prompt\n",
    "    abstract = remove_newlinechar(abstract)\n",
    "    meta_prompt += \"Abstract: \" + abstract + \"\\n\"\n",
    "    return meta_prompt\n",
    "def append_introduction(meta_prompt, introduction):\n",
    "    if (\"[Failed match flag]\" in introduction):\n",
    "        return meta_prompt\n",
    "    introduction = remove_newlinechar(introduction)\n",
    "    meta_prompt += \"Introduction: \" + introduction + \"\\n\"\n",
    "    return meta_prompt\n",
    "def append_conclusion(meta_prompt, conclusion):\n",
    "    if (\"[Failed match flag]\" in conclusion):\n",
    "        return meta_prompt\n",
    "    conclusion = remove_newlinechar(conclusion)\n",
    "    meta_prompt += \"Conclusion: \" + conclusion + \"\\n\"\n",
    "    return meta_prompt\n",
    "def format_meta_prompt(content, level):\n",
    "    meta_prompt = \"\"\n",
    "    meta_prompt = append_title(meta_prompt, content[\"title\"])\n",
    "    meta_prompt = append_authors(meta_prompt, content[\"authors\"])\n",
    "    meta_prompt = append_level(meta_prompt, level)\n",
    "    meta_prompt += \"\\n\"\n",
    "    meta_prompt = append_abstract(meta_prompt, content[\"abstract\"])\n",
    "    meta_prompt += \"\\n\"\n",
    "    meta_prompt = append_introduction(meta_prompt, content[\"introduction\"])\n",
    "    meta_prompt += \"\\n\"\n",
    "    meta_prompt = append_conclusion(meta_prompt, content[\"conclusion\"])\n",
    "    return meta_prompt\n",
    "\n",
    "\n",
    "\n",
    "##### Function for Mateoooooo #################\n",
    "# for level, select from \"child\", \"teenager\", \"undegraduate\", \"graduate\", \"phd\" \n",
    "def poindexter(url, level = \"child\"):\n",
    "    content = fetch_everything(url)\n",
    "    meta_prompt = format_meta_prompt(content, level)\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo-16k\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": meta_prompt},\n",
    "    ],\n",
    "    max_tokens = 500,\n",
    "    temperature = 0.8,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(poindexter(test_url, \"child\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e685daf-7abd-418f-8e38-6bf452e5bcab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248d729-26bc-4a75-8382-2334b881bb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
