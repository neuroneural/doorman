{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee252d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import slack\n",
    "import openai\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask\n",
    "from slackeventsapi import SlackEventAdapter\n",
    "import pandas as pd\n",
    "df = pd.read_csv('QandA_list.csv', encoding='utf-8')\n",
    "answers = df[\"Question answers\"].tolist()\n",
    "env_path = Path('.')/'.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "openai.api_key = token=os.environ['CHAT_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08940d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<OpenAIObject at 0x7f7007fc78d0> JSON: {\n",
      "  \"index\": 0,\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Of course! I'd be happy to help you learn linear algebra. Linear algebra is a branch of mathematics that deals with vector spaces and linear transformations. It involves the study of systems of linear equations, matrices, vectors, and their properties.\\n\\nTo start, let's talk about vectors. A vector is a quantity that has both magnitude and direction. It can be represented geometrically as an arrow in space. In linear algebra, vectors are typically represented as column matrices. For example, the vector [1, 2, 3] can be represented as:\\n\\n| 1 |\\n| 2 |\\n| 3 |\\n\\nVectors can be added together, and scalar multiplication can be applied to them. Addition of vectors is done by adding corresponding entries. Scalar multiplication is multiplying each entry of the vector by a scalar value.\\n\\nNow, let's move on to matrices. A matrix is a rectangular array of numbers, arranged in rows and columns. Matrices are used to represent linear transformations and systems of linear equations. For example, a 2x3 matrix A can be represented as:\\n\\n| a11  a12  a13 |\\n| a21  a22  a23 |\\n\\nTo perform matrix multiplication, the number of columns in the first matrix must be equal to the number of rows in the second matrix. The resulting matrix will then have the same number of rows as the first matrix and the same number of columns as the second matrix.\\n\\nLinear algebra also deals with concepts like determinants, eigenvalues, eigenvectors, and much more. These concepts are used to solve systems of linear equations, understand transformations, and analyze the behavior of vectors and matrices.\\n\\nIs there a specific topic or concept related to linear algebra that you'd like to delve into further?\"\n",
      "  },\n",
      "  \"finish_reason\": \"stop\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "def gpt_test(prompt):\n",
    "\tresponse = openai.ChatCompletion.create(\n",
    "\t\t#Choose model\n",
    "\t\tmodel = \"gpt-3.5-turbo-0613\",\n",
    "\t\t#Define \n",
    "\t\tmessages = [\n",
    "\t\t\t{\"role\": \"system\", \"content\" : \"The user wants to learn math, keep them on the topic of math whenever possible and nudge them in the direction of math whenever they veer off course\"},\n",
    "\t\t\t{\"role\": \"user\", \"content\": prompt},\n",
    "\t\t],\n",
    "\t\tmax_tokens = 500,\n",
    "        temperature = 0.8,\n",
    "\t)\n",
    "\treturn response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f5c618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'd be happy to help you learn linear algebra. Linear algebra is a branch of mathematics that deals with vector spaces and linear transformations. It involves the study of systems of linear equations, matrices, vectors, and their properties.\n",
      "\n",
      "To start, let's talk about vectors. A vector is a quantity that has both magnitude and direction. It can be represented geometrically as an arrow in space. In linear algebra, vectors are typically represented as column matrices. For example, the vector [1, 2, 3] can be represented as:\n",
      "\n",
      "| 1 |\n",
      "| 2 |\n",
      "| 3 |\n",
      "\n",
      "Vectors can be added together, and scalar multiplication can be applied to them. Addition of vectors is done by adding corresponding entries. Scalar multiplication is multiplying each entry of the vector by a scalar value.\n",
      "\n",
      "Now, let's move on to matrices. A matrix is a rectangular array of numbers, arranged in rows and columns. Matrices are used to represent linear transformations and systems of linear equations. For example, a 2x3 matrix A can be represented as:\n",
      "\n",
      "| a11  a12  a13 |\n",
      "| a21  a22  a23 |\n",
      "\n",
      "To perform matrix multiplication, the number of columns in the first matrix must be equal to the number of rows in the second matrix. The resulting matrix will then have the same number of rows as the first matrix and the same number of columns as the second matrix.\n",
      "\n",
      "Linear algebra also deals with concepts like determinants, eigenvalues, eigenvectors, and much more. These concepts are used to solve systems of linear equations, understand transformations, and analyze the behavior of vectors and matrices.\n",
      "\n",
      "Is there a specific topic or concept related to linear algebra that you'd like to delve into further?\n"
     ]
    }
   ],
   "source": [
    "print(string[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6caf9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_test(prompt, current_convo):\n",
    "    messages = [{\"role\": \"system\", \"content\" : \"The user wants to learn about a specific topic, keep them on that topic and try to not let them veer off course. Whenever they might do so offer to open up a separate discussion instead of directly answering them\"},]\n",
    "    messages += current_convo\n",
    "    messages += [{\"role\": \"user\", \"content\": inp}]\n",
    "    for x in messages:\n",
    "        print(x)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        #Choose model\n",
    "        model = \"gpt-3.5-turbo-16k\",\n",
    "        #Define \n",
    "        messages = messages,\n",
    "        max_tokens = 500,\n",
    "        temperature = 0.8)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "963411be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae55119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ I want to learn about linear algebra\n",
      "{'role': 'system', 'content': 'The user wants to learn about a specific topic, keep them on that topic and try to not let them veer off course. Whenever they might do so offer to open up a separate discussion instead of directly answering them'}\n",
      "{'role': 'user', 'content': 'I want to learn about linear algebra'}\n",
      "That's great! Linear algebra is a fascinating subject. It deals with vectors, vector spaces, matrices, and linear transformations. It has wide applications in various fields like computer science, physics, engineering, and economics. What aspect of linear algebra are you interested in learning more about?\n",
      "$ donkey\n",
      "{'role': 'system', 'content': 'The user wants to learn about a specific topic, keep them on that topic and try to not let them veer off course. Whenever they might do so offer to open up a separate discussion instead of directly answering them'}\n",
      "{'role': 'user', 'content': 'I want to learn about linear algebra'}\n",
      "{'role': 'assistant', 'content': \"That's great! Linear algebra is a fascinating subject. It deals with vectors, vector spaces, matrices, and linear transformations. It has wide applications in various fields like computer science, physics, engineering, and economics. What aspect of linear algebra are you interested in learning more about?\"}\n",
      "{'role': 'user', 'content': 'donkey'}\n",
      "I'm sorry, but I'm not sure how donkeys relate to linear algebra. However, if you have any specific questions or if there's something related to linear algebra that you'd like to discuss, I'd be more than happy to help!\n",
      "$ end_conversation\n"
     ]
    }
   ],
   "source": [
    "current_convo =[]\n",
    "inp = \"\"\n",
    "while (True):\n",
    "    inp = input(\"$ \")\n",
    "    if (inp == \"end_conversation\"):\n",
    "        break\n",
    "    output = gpt_test(inp, current_convo)\n",
    "    output_string = output[\"choices\"][0][\"message\"][\"content\"]\n",
    "    current_convo += [{\"role\": \"user\", \"content\": inp}]\n",
    "    current_convo += [{\"role\": \"assistant\", \"content\": output_string}]\n",
    "    print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17565bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_username = \"manh\"\n",
    "#Record schema for querying conversations:\n",
    "#    every user will have a list of records associated with them (optional for now)\n",
    "#    records and their relations stored in a single json file\n",
    "#    every conversation (regardles of branching or not) will be stored in a different json file\n",
    "\"\"\"\n",
    "Schema for user record:\n",
    "{'userID': 'Mike123',\n",
    "'record_list':['record1','record2'],\n",
    "}\n",
    "Schema for record-conversation relation:\n",
    "{'recordID':'record1',\n",
    "'start_conversationID':'cID0',\n",
    "'custom_system_message':'Teach the user linear algebra,\n",
    "                         don't let them veer far from\n",
    "                         the current conversation topic',\n",
    "'record_keywords': ['AI', 'AI applications', 'product mangagement'],\n",
    "}\n",
    "\n",
    "Schema for conversation-conversation relations: %\n",
    "{'conversationID': 'cID1',\n",
    "'parentID': 'cID0'\n",
    "'childrenID': ['cID2', 'cID3'],\n",
    "'time_created':'1231809184',\n",
    "}\n",
    "\n",
    "Schema for conversation-correspondence relations:\n",
    "{'conversationID': 'cID1',\n",
    "'conversationName': 'Linear Algebra',\n",
    "'conversation_keywords: ['math', 'matrices', 'eigenvalues', 'AI'], # ignore this for now\n",
    "'conversation_history': [\n",
    "    [{'role':'user', 'content': 'teach me linear'},\n",
    "     {'role':'assistant'}\n",
    "],\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237981e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Basic info:\n",
    "- model variable defines what model to use. Be careful as different models cost differetly\n",
    "- ChatCompletetion.create() has 3 main roles:\n",
    "    - system: meta-prompt, basically what the software engineers want the model to do\n",
    "    - user: end user input, free form. keep in mind prompt jailbreaking when designing prompts\n",
    "    - assistant: used to plug in arbitrary model output. basically a gas lighting tool, also\n",
    "    useful for creating conversational memory\n",
    "\n",
    "Meta prompt:\n",
    "- Defines basic behavior of model, if calling of functions or returning json output is \n",
    "desired, you have to *verbally* convince the models to use the functions. There is no\n",
    "guarantee, and god knows I have no idea how openAI implements it in the back end\n",
    "\n",
    "Function:\n",
    "- Not a real function, but a mental? verbal? (who knows) algorithm for the model to undergo\n",
    "when doing inference. Model will (or will not) call function depending on wording of meta prompt.\n",
    "Outputs are always defined, though not necessarily will be returned (model will sometimes\n",
    "empty jsons for example). To make it work, use prompt engineering.\n",
    "- For reference, removing \"use only the 'classify' function\" from the meta prompt actually\n",
    "*improved* consistency of the model using the function correctly.\n",
    "- Note: There can be many functions\n",
    "\n",
    "Todo:\n",
    "- Return all model outputs and data (load time, token count, etc) to a json file for \n",
    "documentation and more r&d.\n",
    "\n",
    "--- Everything here is under heavy experimentation, no one knows what's going on and nothing \n",
    "makes any sense ---\n",
    "\"\"\"\n",
    "def doorman(prompt):\n",
    "    #Load meta prompt\n",
    "    with open('llmlads_prompt.txt','r') as file:\n",
    "        meta_prompt = file.read()\n",
    "    #Define API Call\n",
    "    response = openai.ChatCompletion.create(\n",
    "        #Choose model\n",
    "        model = \"gpt-3.5-turbo-16k\",\n",
    "        #Define \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": meta_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        #Define 'function' for model to call during execution\n",
    "        functions = [\n",
    "            {\n",
    "                \"name\": \"classify\",\n",
    "                #Verbal description to help the model use the function correctly,\n",
    "                #for the time being, telling the model to return 0 if no matches are found\n",
    "                #seems to do absolutely nothing\n",
    "                \"description\": \"classify a user statement into one of the statement groups using a json format, output 0 if there are no matches\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"group\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"index of group that the statement most resembles\",\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                #This actually does absolutely nothing, model frequently returns empty json\n",
    "                #anyway, needs further testing\n",
    "                \"required\": [\"group\"],\n",
    "            },\n",
    "        ],\n",
    "        #Define model parameters\n",
    "        max_tokens = 100,\n",
    "        temperature = 0.8,\n",
    "    )\n",
    "    try:\n",
    "        if (response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"] != \"{}\"):\n",
    "            return int(response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"][13:-2])\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e55c2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "slack_event_adapter = SlackEventAdapter(\n",
    "    os.environ['SIGNING_SECRET'], '/slack/events',app)\n",
    "\n",
    "client = slack.WebClient(token=os.environ['SLACK_TOKEN'])\n",
    "#response = client.api_call(\"auth.text\")\n",
    "#BOT_ID = response['user_id']\n",
    "\n",
    "@slack_event_adapter.on('message')\n",
    "def message(payload):\n",
    "    event = payload.get('event',{})\n",
    "    channel_id = event.get('channel')\n",
    "    user_id = event.get('user')\n",
    "    text = event.get('text')\n",
    "    inp = \"User input: \" + \"\\\"\" + text + \"\\\"\"\n",
    "    if user_id != 'U05EY26K3FZ':\n",
    "        index = doorman(inp)\n",
    "        if index == 0:\n",
    "            text = \"Yaabaadabaadoo\"\n",
    "            client.chat_postMessage(channel=channel_id, text=text)\n",
    "        else:\n",
    "            text = answers[index - 1]\n",
    "            client.chat_postMessage(channel=channel_id, text=text)\n",
    "            \n",
    "app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main tesing loop, repeatedly prompts user until user inputs \"end_conversation\"\n",
    "inp = \"\"\n",
    "while (True):\n",
    "    inp = input(\"$ \")\n",
    "    if (inp == \"end_conversation\"):\n",
    "        break\n",
    "    #This formats the prompt to as \"User input 'prompt' \", unclear if it does anything\n",
    "    inp = \"User input: \" + \"\\\"\" + inp + \"\\\"\"\n",
    "    index = doorman(inp)\n",
    "    if index == 0:\n",
    "        print(\"I'm sorry but could you provide me with a bit more clarification?\")\n",
    "    else:\n",
    "        print(answers[index - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156d67de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 88, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 632, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 282, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 229, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 205, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/usr/lib/python3/dist-packages/zmq/sugar/socket.py\", line 214, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 540, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import slack\n",
    "import openai\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask\n",
    "from slackeventsapi import SlackEventAdapter\n",
    "import pandas as pd\n",
    "df = pd.read_csv('QandA_list.csv', encoding='utf-8')\n",
    "answers = df[\"Question answers\"].tolist()\n",
    "\n",
    "env_path = Path('.')/'.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "openai.api_key = token=os.environ['CHAT_TOKEN']\n",
    "\n",
    "def doorman(prompt):\n",
    "    #Load meta prompt\n",
    "    with open('llmlads_prompt.txt','r') as file:\n",
    "        meta_prompt = file.read()\n",
    "    #Define API Call\n",
    "    response = openai.ChatCompletion.create(\n",
    "        #Choose model\n",
    "        model = \"gpt-3.5-turbo-16k\",\n",
    "        #Define \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": meta_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        #Define 'function' for model to call during execution\n",
    "        functions = [\n",
    "            {\n",
    "                \"name\": \"classify\",\n",
    "                #Verbal description to help the model use the function correctly,\n",
    "                #for the time being, telling the model to return 0 if no matches are found\n",
    "                #seems to do absolutely nothing\n",
    "                \"description\": \"classify a user statement into one of the statement groups using a json format, output 0 if there are no matches\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"group\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"index of group that the statement most resembles\",\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                #This actually does absolutely nothing, model frequently returns empty json\n",
    "                #anyway, needs further testing\n",
    "                \"required\": [\"group\"],\n",
    "            },\n",
    "        ],\n",
    "        #Define model parameters\n",
    "        max_tokens = 100,\n",
    "        temperature = 0.8,\n",
    "    )\n",
    "    try:\n",
    "        if (response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"] != \"{}\"):\n",
    "            return int(response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"][13:-2])\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "app = Flask(__name__)\n",
    "slack_event_adapter = SlackEventAdapter(\n",
    "    os.environ['SIGNING_SECRET'], '/slack/events',app)\n",
    "\n",
    "client = slack.WebClient(token=os.environ['SLACK_TOKEN'])\n",
    "#response = client.api_call(\"auth.text\")\n",
    "#BOT_ID = response['user_id']\n",
    "\n",
    "@slack_event_adapter.on('message')\n",
    "def message(payload):\n",
    "    event = payload.get('event',{})\n",
    "    channel_id = event.get('channel')\n",
    "    user_id = event.get('user')\n",
    "    text = event.get('text')\n",
    "    inp = \"User input: \" + \"\\\"\" + text + \"\\\"\"\n",
    "    if user_id != 'U05EY26K3FZ':\n",
    "        index = doorman(inp)\n",
    "        if index == 0:\n",
    "            text = \"I'm sorry but could you provide me with a bit more clarification?\"\n",
    "            client.chat_postMessage(channel=channel_id, text=text)\n",
    "        else:\n",
    "            text = answers[index - 1]\n",
    "            client.chat_postMessage(channel=channel_id, text=text)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
